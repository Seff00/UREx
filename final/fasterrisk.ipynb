{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import pandas as pd\n",
    "from fasterrisk.fasterrisk import RiskScoreOptimizer, RiskScoreClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable names: ['Antibiotic_prophylaxis', 'Sex', 'HCC', 'Ascites', 'Hepatic_encephalopathy', 'Prior_SBP', 'ICU_admission', 'Age_bin_0', 'Age_bin_1', 'Blood_transfused_in_48_hours_u__bin_0', 'Blood_transfused_in_48_hours_u__bin_1', 'Platelet_count_x10_3_uL__bin_0', 'Platelet_count_x10_3_uL__bin_1', 'WBC_x10_3_uL__bin_0', 'WBC_x10_3_uL__bin_1', 'Hemoglobin_g_L__bin_0', 'Hemoglobin_g_L__bin_1', 'INR_bin_0', 'INR_bin_1', 'Na_mEq_L__bin_0', 'Na_mEq_L__bin_1', 'Creatinine_mg_L__bin_0', 'Creatinine_mg_L__bin_1', 'Bilirubin_mg_dL__bin_0', 'Bilirubin_mg_dL__bin_1', 'ALT_IU_L__bin_0', 'ALT_IU_L__bin_1', 'Albumin_g_dL__bin_0', 'Albumin_g_dL__bin_1', 'Systolic_blood_pressure_mmHg__bin_0', 'Systolic_blood_pressure_mmHg__bin_1', 'Heart_rate_beats_min__bin_0', 'Heart_rate_beats_min__bin_1', 'Hospitalization_day__bin_0', 'Hospitalization_day__bin_1', 'Etiology_of_cirrhosis_BC', 'Etiology_of_cirrhosis_HBV', 'Etiology_of_cirrhosis_HCV', 'Etiology_of_cirrhosis_NBNC', 'Etiology_of_bleeding_peptic_ulcer', 'Etiology_of_bleeding_portal_hypertension', 'Treatment_APC', 'Treatment_EIS', 'Treatment_EVL', 'Treatment_no_treatment']\n",
      "X shape: (588, 45)\n",
      "Y shape: (588,)\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv('data_train_infection.csv')\n",
    "# df = pd.read_csv('data_train_rebleeding.csv')\n",
    "# df = pd.read_csv('data_train_mortality.csv')\n",
    "\n",
    "# Define target column\n",
    "target_col = \"infection\"\n",
    "# target_col = \"rebleeding\"\n",
    "# target_col = \"mortality\"\n",
    "\n",
    "# Identify the feature columns\n",
    "feature_cols = [col for col in df.columns if col != target_col]\n",
    "\n",
    "# Create the feature matrix X and target vector Y\n",
    "X = df[feature_cols].values\n",
    "y = df[target_col].values\n",
    "\n",
    "# Create the data dictionary\n",
    "data = {\n",
    "    'variable_names': feature_cols,\n",
    "    'X': X,\n",
    "    'Y': y,\n",
    "    'outcome_name': target_col \n",
    "}\n",
    "\n",
    "print(\"Variable names:\", data['variable_names'])\n",
    "print(\"X shape:\", data['X'].shape)\n",
    "print(\"Y shape:\", data['Y'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['X'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.,\n",
       "        1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,\n",
       "       -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1.,  1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.,\n",
       "        1., -1., -1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1.,  1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1.,  1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = 20       # no. of parameters\n",
    "parent_size = 50    # beam search no. to retain\n",
    "lb=-5\n",
    "ub=5\n",
    "\n",
    "RiskScoreOptimizer_m = RiskScoreOptimizer(X = data['X'], y = data['Y'], k = sparsity, lb=lb, ub=ub, parent_size = parent_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization takes 283.43 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "RiskScoreOptimizer_m.optimize()\n",
    "print(\"Optimization takes {:.2f} seconds.\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We generate 10 risk score models from the sparse diverse pool\n"
     ]
    }
   ],
   "source": [
    "multipliers, intercepts, coefficients = RiskScoreOptimizer_m.get_models()\n",
    "print(\"We generate {} risk score models from the sparse diverse pool\".format(len(multipliers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0: Theoretical score range from -17 to 6\n",
      "Model 1: Theoretical score range from -16 to 4\n",
      "Model 2: Theoretical score range from -16 to 4\n",
      "Model 3: Theoretical score range from -16 to 4\n",
      "Model 4: Theoretical score range from -17 to 5\n",
      "Model 5: Theoretical score range from -16 to 4\n",
      "Model 6: Theoretical score range from -16 to 4\n",
      "Model 7: Theoretical score range from -16 to 4\n",
      "Model 8: Theoretical score range from -16 to 4\n",
      "Model 9: Theoretical score range from -15 to 4\n",
      "Best model index: 0, threshold: -2\n"
     ]
    }
   ],
   "source": [
    "X_train = data['X']\n",
    "y_train = data['Y']\n",
    "\n",
    "best_results = []\n",
    "\n",
    "for i in range(len(coefficients)):\n",
    "    beta = coefficients[i]\n",
    "    intercept = intercepts[i]\n",
    "\n",
    "    # Compute scores (including intercept)\n",
    "    scores_train = X_train @ beta + intercept\n",
    "\n",
    "    # Determine threshold range\n",
    "    max_thresh = int(np.ceil(intercept + np.sum(np.maximum(beta, 0))))\n",
    "    min_thresh = int(np.floor(intercept + np.sum(np.minimum(beta, 0))))\n",
    "    print(f\"Model {i}: Theoretical score range from {min_thresh} to {max_thresh}\")\n",
    "\n",
    "    best_youden = -np.inf\n",
    "    best_thresh = None\n",
    "    best_metrics = {}\n",
    "\n",
    "    # Loop through possible thresholds\n",
    "    for thresh in range(min_thresh, max_thresh + 1):\n",
    "        preds = np.where(scores_train >= thresh, 1, -1)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_train, preds, labels=[-1, 1]).ravel()\n",
    "\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        youden_index = sensitivity + specificity - 1\n",
    "\n",
    "        if youden_index > best_youden:\n",
    "            best_youden = youden_index\n",
    "            best_thresh = thresh\n",
    "            best_metrics = {\n",
    "                'tp': tp,\n",
    "                'fp': fp,\n",
    "                'tn': tn,\n",
    "                'fn': fn,\n",
    "                'sensitivity': sensitivity,\n",
    "                'specificity': specificity,\n",
    "                'threshold': thresh,\n",
    "                'model_idx': i,\n",
    "                'intercept': intercept,\n",
    "                'beta': beta\n",
    "            }\n",
    "\n",
    "    best_results.append(best_metrics)\n",
    "\n",
    "# Select model with best Youden index overall\n",
    "best_model = max(best_results, key=lambda x: x['sensitivity'] + x['specificity'])\n",
    "\n",
    "print(f\"Best model index: {best_model['model_idx']}, threshold: {best_model['threshold']}\")\n",
    "\n",
    "thresh = best_model['threshold']\n",
    "beta = coefficients[best_model['model_idx']]\n",
    "intercept = intercepts[best_model['model_idx']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Train Set Evaluation ===\n",
      "Best model index: 0\n",
      "Threshold: -2\n",
      "TP: 22, FP: 100, TN: 459, FN: 7\n",
      "Accuracy: 0.818\n",
      "Sensitivity (Recall): 0.759\n",
      "Specificity: 0.821\n",
      "Precision: 0.180\n",
      "Negative Predictive Value: 0.985\n",
      "F1 Macro Score: 0.594\n",
      "AUC Score: 0.862\n"
     ]
    }
   ],
   "source": [
    "scores_train = X_train @ beta + intercept\n",
    "\n",
    "preds_train = np.where(scores_train >= thresh, 1, -1)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_train, preds_train, labels=[-1, 1]).ravel()\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0  # Recall\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "\n",
    "# F1 scores for both classes\n",
    "f1_pos = 2 * (precision * sensitivity) / (precision + sensitivity) if (precision + sensitivity) > 0 else 0\n",
    "f1_neg = 2 * (specificity * npv) / (specificity + npv) if (specificity + npv) > 0 else 0\n",
    "f1_macro = (f1_pos + f1_neg) / 2\n",
    "\n",
    "# AUC Score\n",
    "# labels_test should be {1, -1}, convert to {1, 0} for AUC\n",
    "labels_binary = (y_train == 1).astype(int)\n",
    "auc = roc_auc_score(labels_binary, scores_train)\n",
    "\n",
    "print(\"=== Train Set Evaluation ===\")\n",
    "print(f\"Best model index: {best_model['model_idx']}\")\n",
    "print(f\"Threshold: {thresh}\")\n",
    "print(f\"TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}\")\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Sensitivity (Recall): {sensitivity:.3f}\")\n",
    "print(f\"Specificity: {specificity:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Negative Predictive Value: {npv:.3f}\")\n",
    "print(f\"F1 Macro Score: {f1_macro:.3f}\")\n",
    "print(f\"AUC Score: {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable names: ['Antibiotic_prophylaxis', 'Sex', 'HCC', 'Ascites', 'Hepatic_encephalopathy', 'Prior_SBP', 'ICU_admission', 'Age_bin_0', 'Age_bin_1', 'Blood_transfused_in_48_hours_u__bin_0', 'Blood_transfused_in_48_hours_u__bin_1', 'Platelet_count_x10_3_uL__bin_0', 'Platelet_count_x10_3_uL__bin_1', 'WBC_x10_3_uL__bin_0', 'WBC_x10_3_uL__bin_1', 'Hemoglobin_g_L__bin_0', 'Hemoglobin_g_L__bin_1', 'INR_bin_0', 'INR_bin_1', 'Na_mEq_L__bin_0', 'Na_mEq_L__bin_1', 'Creatinine_mg_L__bin_0', 'Creatinine_mg_L__bin_1', 'Bilirubin_mg_dL__bin_0', 'Bilirubin_mg_dL__bin_1', 'ALT_IU_L__bin_0', 'ALT_IU_L__bin_1', 'Albumin_g_dL__bin_0', 'Albumin_g_dL__bin_1', 'Systolic_blood_pressure_mmHg__bin_0', 'Systolic_blood_pressure_mmHg__bin_1', 'Heart_rate_beats_min__bin_0', 'Heart_rate_beats_min__bin_1', 'Hospitalization_day__bin_0', 'Hospitalization_day__bin_1', 'Etiology_of_cirrhosis_BC', 'Etiology_of_cirrhosis_HBV', 'Etiology_of_cirrhosis_HCV', 'Etiology_of_cirrhosis_NBNC', 'Etiology_of_bleeding_peptic_ulcer', 'Etiology_of_bleeding_portal_hypertension', 'Treatment_APC', 'Treatment_EIS', 'Treatment_EVL', 'Treatment_no_treatment']\n",
      "X shape: (253, 45)\n",
      "Y shape: (253,)\n"
     ]
    }
   ],
   "source": [
    "# Load your test dataset\n",
    "test_df = pd.read_csv('data_test_infection.csv')\n",
    "# test_df = pd.read_csv('data_train_rebleeding.csv')\n",
    "# test_df = pd.read_csv('data_train_mortality.csv')\n",
    "\n",
    "# Define target column\n",
    "target_col = \"infection\"\n",
    "# target_col = \"rebleeding\"\n",
    "# target_col = \"mortality\"\n",
    "\n",
    "# Identify the feature columns\n",
    "feature_cols = [col for col in test_df.columns if col != target_col]\n",
    "\n",
    "# Create the feature matrix X and target vector Y\n",
    "X = test_df[feature_cols].values\n",
    "y = test_df[target_col].values\n",
    "\n",
    "# Create the data dictionary as expected by RiskSLIM\n",
    "data_test = {\n",
    "    'variable_names': feature_cols,\n",
    "    'X': X,\n",
    "    'Y': y,\n",
    "    'outcome_name': target_col \n",
    "}\n",
    "\n",
    "print(\"Variable names:\", data_test['variable_names'])\n",
    "print(\"X shape:\", data_test['X'].shape)\n",
    "print(\"Y shape:\", data_test['Y'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Set Evaluation ===\n",
      "Best model index: 0\n",
      "Threshold: -2\n",
      "TP: 5, FP: 41, TN: 199, FN: 8\n",
      "Accuracy: 0.806\n",
      "Sensitivity (Recall): 0.385\n",
      "Specificity: 0.829\n",
      "Precision: 0.109\n",
      "Negative Predictive Value: 0.961\n",
      "F1 Macro Score: 0.530\n",
      "AUC Score: 0.684\n"
     ]
    }
   ],
   "source": [
    "X_test = data_test['X']\n",
    "y_test = data_test['Y']\n",
    "scores_test = X_test @ beta + intercept\n",
    "\n",
    "preds_test = np.where(scores_test >= thresh, 1, -1)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds_test, labels=[-1, 1]).ravel()\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0  # Recall\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "\n",
    "# F1 scores for both classes\n",
    "f1_pos = 2 * (precision * sensitivity) / (precision + sensitivity) if (precision + sensitivity) > 0 else 0\n",
    "f1_neg = 2 * (specificity * npv) / (specificity + npv) if (specificity + npv) > 0 else 0\n",
    "f1_macro = (f1_pos + f1_neg) / 2\n",
    "\n",
    "# AUC Score\n",
    "# labels_test should be {1, -1}, convert to {1, 0} for AUC\n",
    "labels_binary = (y_test == 1).astype(int)\n",
    "auc = roc_auc_score(labels_binary, scores_test)\n",
    "\n",
    "print(\"=== Test Set Evaluation ===\")\n",
    "print(f\"Best model index: {best_model['model_idx']}\")\n",
    "print(f\"Threshold: {thresh}\")\n",
    "print(f\"TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}\")\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Sensitivity (Recall): {sensitivity:.3f}\")\n",
    "print(f\"Specificity: {specificity:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Negative Predictive Value: {npv:.3f}\")\n",
    "print(f\"F1 Macro Score: {f1_macro:.3f}\")\n",
    "print(f\"AUC Score: {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fasterrisk method of prediction\n",
    "\n",
    "    predict(self, X):\n",
    "        y_score = (self.intercept + X.dot(self.coefficients)) / self.multiplier\n",
    "        y_pred = 2 * (y_score > 0) - 1\n",
    "        return y_pred\n",
    "\n",
    "not used as it assumes the threshold to be 0\n",
    "\n",
    "left here as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test are predicted to be [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "model_index = best_model['model_idx']\n",
    "multiplier = multipliers[model_index]\n",
    "intercept = intercepts[model_index]\n",
    "coefficient = coefficients[model_index]\n",
    "\n",
    "# print(model_index)\n",
    "# print(multiplier)\n",
    "# print(intercept)\n",
    "# print(coefficient)\n",
    "\n",
    "RiskScoreClassifier_m = RiskScoreClassifier(multiplier, intercept, coefficient, X_train = X_train)\n",
    "y_test_pred = RiskScoreClassifier_m.predict(data_test['X'])\n",
    "print(\"y_test are predicted to be {}\".format(y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "diff = np.setdiff1d(y_test_pred, preds_test)\n",
    "print(diff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
